{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e7074e",
   "metadata": {},
   "source": [
    "# Start Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe18b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "torch.__version__\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0137c535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yizhou\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "user = getpass.getuser()\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d56ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usd_path = f\"omniverse://localhost/Users/{user}/uva_sac.usd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e8d7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting kit application with the fillowing args:  ['/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/exts/omni.isaac.kit/omni/isaac/kit/simulation_app.py', '/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/apps/omni.isaac.sim.python.kit', '--/app/tokens/exe-path=/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/kit', '--/persistent/app/viewport/displayOptions=3094', '--/rtx/materialDb/syncLoads=True', '--/rtx/hydra/materialSyncLoads=True--/omni.kit.plugin/syncUsdLoads=True', '--/app/renderer/resolution/width=1280', '--/app/renderer/resolution/height=720', '--/app/window/width=1440', '--/app/window/height=900', '--/renderer/multiGpu/enabled=True', '--ext-folder', '/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/exts', '--ext-folder', '/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/apps', '--/physics/cudaDevice=0', '--portable', '--no-window']\n",
      "Passing the following args to the base kit application:  ['-f', '/home/yizhou/.local/share/jupyter/runtime/kernel-2fed25f9-a2d9-490a-aed1-cdc2ef51b80f.json']\n",
      "[Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.\n",
      "[Info] [carb] Logging to file: /home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/kit/logs/Kit/Isaac-Sim/2022.1/kit_20221224_103119.log\n",
      "2022-12-24 18:31:19 [4ms] [Warning] [omni.ext.plugin] [ext: omni.drivesim.sensors.nv.lidar] Extensions config 'extension.toml' doesn't exist '/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/exts/omni.drivesim.sensors.nv.lidar' or '/home/yizhou/.local/share/ov/pkg/isaac_sim-2022.1.1/exts/omni.drivesim.sensors.nv.lidar/config'\n",
      "[0.084s] [ext: omni.stats-0.0.0] startup\n",
      "[0.130s] [ext: omni.gpu_foundation-0.0.0] startup\n",
      "2022-12-24 18:31:19 [129ms] [Warning] [carb] FrameworkImpl::setDefaultPlugin(client: omni.gpu_foundation_factory.plugin, desc : [carb::graphics::Graphics v2.5], plugin : carb.graphics-vulkan.plugin) failed. Plugin selection is locked, because the interface was previously acquired by: \n",
      "[0.139s] [ext: carb.windowing.plugins-1.0.0] startup\n",
      "[0.151s] [ext: omni.assets.plugins-0.0.0] startup\n",
      "[0.152s] [ext: omni.kit.renderer.init-0.0.0] startup\n",
      "\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Driver Version: 510.108.3     | Graphics API: Vulkan\n",
      "|=============================================================================================|\n",
      "| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |\n",
      "|     |                                  |        |     |            | Device-ID | UUID       |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 0   | NVIDIA GeForce RTX 3090          | Yes: 0 |     | 24822   MB | 10de      | 0          |\n",
      "|     |                                  |        |     |            | 2204      | 3f50dd6e.. |\n",
      "|=============================================================================================|\n",
      "| OS: Linux yizhou-Z370-AORUS-Gaming-5, Version: 5.15.0-56-generic\n",
      "| Processor: Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz | Cores: Unknown | Logical: 12\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Total Memory (MB): 32044 | Free Memory: 27156\n",
      "| Total Page/Swap (MB): 2047 | Free Page/Swap: 2047\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "2022-12-24 18:31:20 [876ms] [Warning] [carb.cudainterop.plugin] On Linux only, CUDA and the display driver does not support IOMMU-enabled bare-metal PCIe peer to peer memory copy.\n",
      "However, CUDA and the display driver does support IOMMU via VM pass through. As a consequence, users on Linux,\n",
      "when running on a native bare metal system, should disable the IOMMU. The IOMMU should be enabled and the VFIO driver\n",
      "be used as a PCIe pass through for virtual machines.\n",
      "[0.897s] [ext: omni.kit.pipapi-0.0.0] startup\n",
      "[0.907s] [ext: omni.kit.pip_archive-0.0.0] startup\n",
      "[0.911s] [ext: omni.isaac.core_archive-1.2.0] startup\n",
      "[0.929s] [ext: omni.usd.config-1.0.0] startup\n",
      "[0.931s] [ext: omni.usd.libs-1.0.0] startup\n",
      "[1.059s] [ext: omni.kit.pip_torch-1_11_0-0.1.3] startup\n",
      "[1.091s] [ext: omni.isaac.ml_archive-1.1.0] startup\n",
      "[1.160s] [ext: omni.kit.loop-isaac-0.1.0] startup\n",
      "[1.160s] [ext: omni.kit.async_engine-0.0.0] startup\n",
      "[1.162s] [ext: omni.appwindow-1.0.0] startup\n",
      "[1.167s] [ext: omni.client-0.1.0] startup\n",
      "[1.180s] [ext: omni.kit.test-0.0.0] startup\n",
      "[1.181s] [ext: omni.kit.renderer.core-0.0.0] startup\n",
      "[1.253s] [ext: omni.ui-2.10.3] startup\n",
      "[1.270s] [ext: carb.audio-0.1.0] startup\n",
      "[1.273s] [ext: omni.kit.mainwindow-0.0.0] startup\n",
      "[1.275s] [ext: omni.uiaudio-1.0.0] startup\n",
      "[1.276s] [ext: omni.kit.uiapp-0.0.0] startup\n",
      "[1.276s] [ext: omni.usd.schema.physics-1.0.0] startup\n",
      "[1.319s] [ext: omni.usd.schema.audio-0.0.0] startup\n",
      "[1.326s] [ext: omni.usd.schema.semantics-0.0.0] startup\n",
      "[1.337s] [ext: omni.usd.schema.omnigraph-1.0.0] startup\n",
      "[1.347s] [ext: omni.usd.schema.anim-0.0.0] startup\n",
      "[1.388s] [ext: omni.kit.commands-1.2.2] startup\n",
      "[1.393s] [ext: omni.timeline-1.0.2] startup\n",
      "[1.395s] [ext: omni.hydra.scene_delegate-0.2.0] startup\n",
      "[1.403s] [ext: omni.kit.audiodeviceenum-1.0.0] startup\n",
      "[1.405s] [ext: omni.usd-1.5.3] startup\n",
      "[1.462s] [ext: omni.kit.asset_converter-1.2.31] startup\n",
      "[1.477s] [ext: omni.usd.schema.physx-0.0.0] startup\n",
      "[1.545s] [ext: omni.usd.schema.isaac-0.2.0] startup\n",
      "[1.587s] [ext: omni.usd.schema.forcefield-0.0.0] startup\n",
      "[1.595s] [ext: omni.kvdb-0.0.0] startup\n",
      "[1.597s] [ext: omni.usdphysics-1.4.15] startup\n",
      "[1.601s] [ext: omni.graph.tools-1.4.0] startup\n",
      "[1.625s] [ext: omni.localcache-0.0.0] startup\n",
      "[1.628s] [ext: omni.kit.stage_templates-1.1.2] startup\n",
      "[1.630s] [ext: omni.convexdecomposition-1.4.15] startup\n",
      "[1.633s] [ext: omni.physics.tensors-0.1.0] startup\n",
      "[1.640s] [ext: omni.physx-1.4.15-5.1] startup\n",
      "[1.690s] [ext: omni.graph.core-2.29.1] startup\n",
      "[1.709s] [ext: omni.kit.menu.utils-1.2.11] startup\n",
      "[1.727s] [ext: omni.physx.tensors-0.1.0] startup\n",
      "[1.734s] [ext: omni.graph-1.23.0] startup\n",
      "[1.784s] [ext: omni.kit.numpy.common-0.1.0] startup\n",
      "[1.786s] [ext: omni.kit.window.script_editor-1.6.2] startup\n",
      "[1.799s] [ext: omni.kit.search_core-1.0.2] startup\n",
      "[1.802s] [ext: omni.isaac.dynamic_control-1.1.0] startup\n",
      "[1.811s] [ext: omni.kit.renderer.capture-0.0.0] startup\n",
      "[1.816s] [ext: omni.kit.widget.filebrowser-2.2.27] startup\n",
      "[1.823s] [ext: omni.kit.widget.path_field-2.0.3] startup\n",
      "[1.825s] [ext: omni.kit.notification_manager-1.0.5] startup\n",
      "[1.827s] [ext: omni.kit.widget.versioning-1.3.8] startup\n",
      "[1.829s] [ext: omni.kit.widget.browser_bar-2.0.3] startup\n",
      "[1.831s] [ext: omni.kit.window.popup_dialog-2.0.8] startup\n",
      "[1.833s] [ext: omni.mdl.neuraylib-0.1.0] startup\n",
      "[1.836s] [ext: omni.kit.window.filepicker-2.4.30] startup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OmniAssetFileFormat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp initialized:\n",
      "   Version: 0.2.2\n",
      "   CUDA device: NVIDIA GeForce RTX 3090\n",
      "   Kernel cache: /home/yizhou/.cache/warp/0.2.2\n",
      "[1.890s] [ext: omni.kit.menu.create-1.0.2] startup\n",
      "[1.891s] [ext: omni.mdl-0.1.0] startup\n",
      "[1.914s] [ext: omni.kit.window.file_importer-1.0.4] startup\n",
      "[1.915s] [ext: omni.kit.window.file_exporter-1.0.4] startup\n",
      "[1.917s] [ext: omni.kit.material.library-1.3.10] startup\n",
      "[1.922s] [ext: omni.kit.window.drop_support-1.0.0] startup\n",
      "[1.923s] [ext: omni.kit.window.file-1.3.16] startup\n",
      "[1.925s] [ext: omni.kit.context_menu-1.3.9] startup\n",
      "[1.929s] [ext: omni.kit.window.property-1.6.3] startup\n",
      "[1.930s] [ext: omni.kit.window.content_browser-2.4.28] startup\n",
      "[1.941s] [ext: omni.kit.widget.stage-2.6.15] startup\n",
      "[1.945s] [ext: omni.isaac.version-1.0.0] startup\n",
      "[1.946s] [ext: omni.kit.property.usd-3.14.9] startup\n",
      "[1.981s] [ext: omni.kit.viewport.legacy_gizmos-1.0.0] startup\n",
      "[1.984s] [ext: omni.hydra.rtx-0.1.0] startup\n",
      "[1.995s] [ext: omni.renderer-rtx-0.0.0] startup\n",
      "[1.995s] [ext: omni.hydra.engine.stats-1.0.0] startup\n",
      "[2.002s] [ext: omni.debugdraw-0.1.0] startup\n",
      "[2.008s] [ext: omni.kit.widget.settings-1.0.0] startup\n",
      "[2.009s] [ext: omni.kit.window.viewport-0.0.0] startup\n",
      "[6.331s] [ext: omni.kit.widget.prompt-1.0.1] startup\n",
      "[6.332s] [ext: omni.kit.widget.graph-1.4.3] startup\n",
      "[6.403s] [ext: omni.kit.window.preferences-1.2.1] startup\n",
      "[6.443s] [ext: omni.ui_query-1.1.1] startup\n",
      "[6.446s] [ext: omni.graph.ui-1.6.1] startup\n",
      "[6.474s] [ext: omni.kit.ui_test-1.2.2] startup\n",
      "[6.476s] [ext: omni.graph.action-1.18.0] startup\n",
      "[6.489s] [ext: omni.kit.widget.searchfield-1.0.6] startup\n",
      "[6.490s] [ext: omni.kit.usd_undo-0.1.0] startup\n",
      "[6.492s] [ext: omni.graph.scriptnode-0.5.0] startup\n",
      "[6.494s] [ext: omni.physx.commands-1.4.15-5.1] startup\n",
      "[6.500s] [ext: omni.graph.nodes-1.26.0] startup\n",
      "[6.520s] [ext: omni.command.usd-1.0.1] startup\n",
      "[6.523s] [ext: omni.kit.window.extensions-1.1.0] startup\n",
      "[6.529s] [ext: omni.syntheticdata-0.2.1] startup\n",
      "[6.554s] [ext: omni.kit.primitive.mesh-1.0.0] startup\n",
      "[6.558s] [ext: omni.warp-0.2.2] startup\n",
      "[6.701s] [ext: omni.isaac.ui-0.2.1] startup\n",
      "[6.703s] [ext: omni.replicator.core-1.4.3] startup\n",
      "[6.915s] [ext: omni.isaac.core-1.24.3] startup\n",
      "[7.007s] [ext: omni.physx.ui-1.4.15-5.1] startup\n",
      "[7.090s] [ext: omni.kit.property.material-1.8.5] startup\n",
      "[7.094s] [ext: omni.kit.window.toolbar-1.2.4] startup\n",
      "[7.101s] [ext: omni.isaac.core_nodes-0.13.0] startup\n",
      "[7.115s] [ext: omni.physx.demos-1.4.15-5.1] startup\n",
      "[7.119s] [ext: omni.kit.property.physx-0.1.0] startup\n",
      "2022-12-24 18:31:26 [7,182ms] [Warning] [omni.physx.plugin] Deprecated: getSimulationEventStream is deprecated, please use getSimulationEventStreamV2\n",
      "[7.192s] [ext: omni.physx.tests-1.4.15-5.1] startup\n",
      "[7.466s] [ext: omni.isaac.wheeled_robots-0.5.8] startup\n",
      "[7.476s] [ext: omni.kit.menu.common-1.0.0] startup\n",
      "[7.477s] [ext: omni.physx.vehicle-1.4.15-5.1] startup\n",
      "[7.489s] [ext: omni.physx.cct-1.4.15-5.1] startup\n",
      "[7.565s] [ext: omni.physx.camera-1.4.15-5.1] startup\n",
      "[7.573s] [ext: omni.kit.widget.stage_icons-1.0.2] startup\n",
      "[7.574s] [ext: omni.ui.scene-1.5.0] startup\n",
      "[7.580s] [ext: omni.physx.bundle-1.4.15-5.1] startup\n",
      "[7.580s] [ext: omni.kit.window.stage-2.3.7] startup\n",
      "[7.583s] [ext: omni.replicator.composer-1.1.3] startup\n",
      "[7.599s] [ext: omni.isaac.lula-1.1.0] startup\n",
      "[7.608s] [ext: omni.rtx.window.settings-0.6.1] startup\n",
      "[7.613s] [ext: omni.isaac.surface_gripper-0.1.2] startup\n",
      "[7.618s] [ext: omni.isaac.motion_planning-0.2.0] startup\n",
      "[7.626s] [ext: omni.rtx.settings.core-0.5.5] startup\n",
      "[7.631s] [ext: omni.isaac.manipulators-1.0.1] startup\n",
      "[7.632s] [ext: omni.isaac.motion_generation-3.6.1] startup\n",
      "[7.638s] [ext: omni.kit.widget.zoombar-1.0.3] startup\n",
      "[7.639s] [ext: omni.kit.graph.delegate.default-1.0.15] startup\n",
      "[7.641s] [ext: omni.isaac.franka-0.3.0] startup\n",
      "[7.642s] [ext: omni.kit.browser.core-2.0.12] startup\n",
      "[7.646s] [ext: omni.kit.graph.editor.core-1.3.3] startup\n",
      "[7.648s] [ext: omni.kit.graph.usd.commands-1.1.0] startup\n",
      "[7.649s] [ext: omni.kit.browser.folder.core-1.1.13] startup\n",
      "[7.652s] [ext: omni.kit.graph.widget.variables-2.0.2] startup\n",
      "[7.653s] [ext: omni.kit.graph.delegate.modern-1.6.0] startup\n",
      "[7.654s] [ext: omni.kit.selection-0.1.0] startup\n",
      "[7.655s] [ext: omni.isaac.debug_draw-0.Opening usd file at  omniverse://localhost/Users/yizhou/uva_sac.usd  ...Done.\n",
      "Saving a temp livesync stage at  omniverse://localhost/Users/yizhou/uva_sac.usd  ...Done.\n"
     ]
    }
   ],
   "source": [
    "from omni.isaac.kit import SimulationApp    \n",
    "simulation_app = SimulationApp({\"headless\": True, \"open_usd\": usd_path,  \"livesync_usd\": usd_path}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log level\n",
    "import logging\n",
    "import carb\n",
    "\n",
    "logging.getLogger(\"omni.hydra\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"omni.isaac.urdf\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"omni.physx.plugin\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"omni.isaac.synthetic_utils\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"omni.isaac.synthetic_utils.syntheticdata\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"omni.hydra.scene_delegate.plugin\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "l = carb.logging.LEVEL_ERROR\n",
    "carb.settings.get_settings().set(\"/log/level\", l)\n",
    "carb.settings.get_settings().set(\"/log/fileLogLevel\", l)\n",
    "carb.settings.get_settings().set(\"/log/outputStreamLevel\", l)\n",
    "\n",
    "# # This logged error is printed as it should\n",
    "# carb.log_error(\"ERROR\")\n",
    "# # This warning is printed but should not\n",
    "# carb.log_warn(\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34671d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491f4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task.config import DATA_PATH, FEATURE_PATH\n",
    "task_type = \"Table\"\n",
    "side_choice = \"Border\"\n",
    "base_asset_id = 0\n",
    "load_nucleus = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadd32bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11192/1188747208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pause' is not defined"
     ]
    }
   ],
   "source": [
    "pause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475ee6a",
   "metadata": {},
   "source": [
    "# Init Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fd193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uva_env import UvaEnv\n",
    "env = UvaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e665fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task.utils import add_scene_default\n",
    "add_scene_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(env.stage.TraverseAll()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaeb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.clean()\n",
    "env.world.step(render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c365e3",
   "metadata": {},
   "source": [
    "# Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task.scene import ArrangeScene\n",
    "scene = ArrangeScene(task_type, side_choice, base_asset_id = 0, traj_id = 0, load_nucleus = load_nucleus)\n",
    "env.scene = scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae909b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add base\n",
    "scene.add_base_asset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add room\n",
    "# scene.add_room()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99481529",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.world.step(render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd24034",
   "metadata": {},
   "source": [
    "# Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uv.reward import Rewarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35761844",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewarder = Rewarder(env.world)\n",
    "env.rewarder = rewarder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8bada",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render.helper import RenderHelper\n",
    "render = RenderHelper(task_type, side_choice)\n",
    "\n",
    "render.add_task_cameras()\n",
    "render.set_cameras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d05f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faba50",
   "metadata": {},
   "source": [
    "#  Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from learning.network.resnet import ResNetFeatureExtractor\n",
    "\n",
    "# feature extraction\n",
    "from learning.utils import extract_image_clip_feature_and_save, obtain_action_from_trainer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "feature_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "feature_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958da617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer\n",
    "import json\n",
    "from learning.replay_buffer import ReplayBuffer\n",
    "from learning.config import *\n",
    "\n",
    "buffer = ReplayBuffer(max_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7314c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "from learning.network.sac import *\n",
    "\n",
    "policy = Policy()\n",
    "\n",
    "qf1 = QFunction()\n",
    "qf2 = QFunction()\n",
    "target_qf1 = QFunction()\n",
    "target_qf2 = QFunction()\n",
    "\n",
    "from learning.sac_trainer import SACTrainer\n",
    "\n",
    "trainer = SACTrainer(policy, qf1, qf2, target_qf1, target_qf2, \n",
    "     use_automatic_entropy_tuning = False, \n",
    "     policy_lr=1e-3, \n",
    "     qf_lr=1e-3,\n",
    "     target_update_period = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93eef8c",
   "metadata": {},
   "source": [
    "# Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_network = True\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_traj = 0\n",
    "total_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33335313",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9049e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj config\n",
    "for traj_id in range(200):\n",
    "    total_traj += 1\n",
    "    \n",
    "    base_asset_id = 0\n",
    "    env.scene.base_asset_id = base_asset_id\n",
    "    env.scene.traj_id = traj_id\n",
    "    image_folder = os.path.join(DATA_PATH, task_type, side_choice, str(traj_id))\n",
    "\n",
    "    # base\n",
    "    # scene.add_base_asset()\n",
    "    env.world.step(render = True)\n",
    "\n",
    "    # get images\n",
    "    env.world.render()\n",
    "    images = render.get_images()\n",
    "    render.save_rgb(images[0]['rgb'], image_folder, \"0\")\n",
    "    \n",
    "    ## extract feature\n",
    "    \n",
    "#     extract_image_feature_and_save(images[0]['rgb'][:,:,:3], \n",
    "#         feature_extractor, os.path.join(image_folder, str(0) + \".pt\"))\n",
    "    extract_image_clip_feature_and_save(f\"{image_folder}/{0}.png\", feature_model, feature_processor, \n",
    "        f\"{image_folder}/{0}.pt\",)\n",
    "    \n",
    "\n",
    "    # trajectory\n",
    "    for step in range(5):\n",
    "        total_step += 1\n",
    "        \n",
    "        # sample an object\n",
    "        env.add_scene_obj(mode = \"random\")\n",
    "        \n",
    "        # TODO: get action from sampling\n",
    "        if not use_network or total_traj < 10 or np.random.rand() < 0.2:\n",
    "            x, y = np.tanh(np.random.randn()), np.tanh(np.random.randn())\n",
    "        else:\n",
    "            image_feature_file = f\"{image_folder}/{step}.pt\"\n",
    "            \n",
    "            object_info = env.scene.objects[-1]\n",
    "            object_type = object_info[\"type\"]\n",
    "            obj_name = object_info[\"name\"][:-4]\n",
    "            object_feature_file = os.path.join(FEATURE_PATH, object_type, obj_name + \".pt\")\n",
    "            x, y = obtain_action_from_trainer(image_feature_file, object_feature_file, trainer)\n",
    "        \n",
    "        # load the object into the scene\n",
    "        env.put_last_object((x, y)) \n",
    "        env.world.step(render=True)\n",
    "        \n",
    "        # register the object to the world for physics update\n",
    "        env.register_last_object()\n",
    "        env.world.step(render=True)\n",
    "\n",
    "        # get images\n",
    "        env.world.render()\n",
    "        images = render.get_images()\n",
    "        render.save_rgb(images[0]['rgb'], image_folder, str(step + 1))\n",
    "\n",
    "        ## calculate reward\n",
    "        env.calculate_last_reward(simulation_step = 30)\n",
    "        \n",
    "        ## extract feature\n",
    "#         extract_image_feature_and_save(images[0]['rgb'][:,:,:3], \n",
    "#             feature_extractor, os.path.join(image_folder, str(step + 1) + \".pt\"))\n",
    "        extract_image_clip_feature_and_save(f\"{image_folder}/{step + 1}.png\", feature_model, feature_processor, \n",
    "            f\"{image_folder}/{step + 1}.pt\",)\n",
    "    \n",
    "\n",
    "        ## reset\n",
    "        env.world.reset()\n",
    "        env.world.step(render=True)\n",
    "        \n",
    "        ## trainer nework\n",
    "        if use_network and total_step % UPDATE_TRAINER_STEPS == 0 and total_traj > 5:\n",
    "            batch = buffer.sample_batch(batch_size = BATCH_SIZE)\n",
    "            trainer.update(batch)\n",
    "            \n",
    "            if debug:\n",
    "                rewards = batch['rewards'].to(device)\n",
    "                terminals = batch['terminals'].to(device)\n",
    "                obs = batch['observations'].to(device)\n",
    "                actions = batch['actions'].to(device)\n",
    "                next_obs = batch['next_observations'].to(device)\n",
    "                obj_features = batch['object_features'].to(device)\n",
    "                \n",
    "                dist = trainer.policy(obs, obj_features)\n",
    "                pred = trainer.qf1(obs, obj_features, actions)\n",
    "                print(f\"debug {total_traj}/{total_step}\", #\"\\n dist: \", dist.mean.flatten().tolist(), dist.stddev.flatten().tolist(),\n",
    "                      \"\\n pred:\", pred.flatten().tolist(),\n",
    "                      \"\\n rewards: \", rewards.flatten().tolist())\n",
    "\n",
    "\n",
    "    # Record\n",
    "    record = env.scene.get_scene_data()\n",
    "    env.scene.save_scene_data()\n",
    "    # print(\"record: \", record)\n",
    "    \n",
    "    # Add record to buffer\n",
    "    buffer.add_scene_sample(record)\n",
    "\n",
    "    # Reset (env clean)\n",
    "    env.clean(clean_all = False)\n",
    "    env.step(render = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11155e93",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images\n",
    "env.world.render()\n",
    "env.world.render()\n",
    "images = render.get_images()\n",
    "\n",
    "Image.fromarray(images[0]['rgb'], \"RGBA\").resize((300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3687f5",
   "metadata": {},
   "source": [
    "##  Debug Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d01e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from learning.replay_buffer import ReplayBuffer\n",
    "\n",
    "buffer = ReplayBuffer(max_size=1000)\n",
    "\n",
    "for i in range(100):\n",
    "    replay = json.load(open(f\"{DATA_PATH}/{task_type}/{side_choice}/{i}/scene.json\"))\n",
    "    buffer.add_scene_sample(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec87318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6626c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "from learning.network.sac import *\n",
    "\n",
    "policy = Policy()\n",
    "\n",
    "qf1 = QFunction()\n",
    "qf2 = QFunction()\n",
    "\n",
    "target_qf1 = QFunction()\n",
    "target_qf1.eval()\n",
    "\n",
    "target_qf2 = QFunction()\n",
    "target_qf2.eval()\n",
    "\n",
    "from learning.sac_trainer import SACTrainer\n",
    "\n",
    "trainer = SACTrainer(policy, qf1, qf2, target_qf1, target_qf2, \n",
    "     use_automatic_entropy_tuning = True, \n",
    "     policy_lr=1e-3, \n",
    "     qf_lr=1e-3,\n",
    "     target_update_period = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0acc75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be95f838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " dist   :  [0.108, 0.162, 0.131, 0.232, 0.12, 0.253, 0.145, 0.269, 0.148, 0.285, 0.14, 0.282] [0.715, 0.722, 0.637, 0.664, 0.617, 0.627, 0.586, 0.598, 0.568, 0.587, 0.575, 0.598] \n",
      " pred   : [-0.491, -0.205, -0.287, 0.446, -0.151, -0.207] \n",
      " rewards:  [-0.839, -0.839, -0.832, 1.0, -0.839, -0.839]\n",
      "10 \n",
      " dist   :  [0.213, 0.162, 0.187, 0.148, 0.24, 0.124, 0.116, 0.191, 0.19, 0.154, 0.256, 0.189] [0.541, 0.501, 0.585, 0.558, 0.583, 0.553, 0.564, 0.537, 0.576, 0.551, 0.508, 0.495] \n",
      " pred   : [1.274, 1.34, -0.209, 0.233, -0.079, -0.356] \n",
      " rewards:  [1.0, 0.899, -0.839, -0.839, -0.839, -0.839]\n",
      "20 \n",
      " dist   :  [0.136, 0.121, 0.12, 0.117, 0.092, 0.113, 0.114, 0.135, 0.102, 0.139, 0.093, 0.078] [0.518, 0.471, 0.55, 0.509, 0.543, 0.47, 0.519, 0.471, 0.503, 0.441, 0.625, 0.579] \n",
      " pred   : [-0.297, -0.125, 0.389, 1.293, -0.196, -0.089] \n",
      " rewards:  [-0.839, -0.839, -0.839, 0.953, -0.839, -0.839]\n",
      "30 \n",
      " dist   :  [0.047, 0.366, 0.103, 0.232, 0.103, 0.316, 0.105, 0.328, 0.119, 0.239, -0.013, 0.326] [0.434, 0.35, 0.541, 0.466, 0.454, 0.37, 0.44, 0.359, 0.522, 0.453, 0.493, 0.413] \n",
      " pred   : [1.487, -0.011, 1.629, -0.149, 0.566, 1.507] \n",
      " rewards:  [1.0, -0.839, 1.0, -0.839, -0.635, 1.0]\n",
      "40 \n",
      " dist   :  [0.224, 0.289, 0.23, 0.38, 0.236, 0.339, 0.132, 0.39, 0.231, 0.378, 0.221, 0.353] [0.495, 0.407, 0.421, 0.321, 0.448, 0.341, 0.437, 0.35, 0.423, 0.322, 0.45, 0.354] \n",
      " pred   : [-0.33, -0.433, -0.545, 1.104, 0.959, -0.044] \n",
      " rewards:  [-0.839, -0.839, -0.839, 0.357, 1.0, -0.839]\n",
      "50 \n",
      " dist   :  [0.046, 0.186, 0.074, 0.324, 0.012, 0.315, 0.068, 0.306, 0.059, 0.29, 0.048, 0.261] [0.651, 0.567, 0.476, 0.381, 0.496, 0.411, 0.493, 0.401, 0.521, 0.424, 0.562, 0.462] \n",
      " pred   : [-0.26, 0.325, 0.28, 0.972, -0.141, -0.253] \n",
      " rewards:  [-0.839, -0.839, -0.839, 1.0, -0.839, -0.839]\n",
      "60 \n",
      " dist   :  [-0.008, 0.386, -0.008, 0.42, -0.007, 0.409, 0.012, 0.315, -0.011, 0.408, -0.008, 0.489] [0.409, 0.344, 0.375, 0.311, 0.379, 0.321, 0.464, 0.4, 0.388, 0.319, 0.308, 0.249] \n",
      " pred   : [1.363, -0.489, -0.535, -0.291, -0.256, -0.618] \n",
      " rewards:  [0.994, -0.839, -0.839, -0.839, -0.839, -0.839]\n",
      "70 \n",
      " dist   :  [0.052, 0.252, 0.063, 0.282, 0.048, 0.232, 0.059, 0.264, 0.065, 0.294, 0.049, 0.076] [0.453, 0.421, 0.41, 0.368, 0.49, 0.439, 0.433, 0.391, 0.394, 0.353, 0.72, 0.682] \n",
      " pred   : [1.274, -0.062, -0.525, 1.722, 1.036, -1.457] \n",
      " rewards:  [0.997, -0.839, -0.839, 1.0, 1.0, -0.839]\n",
      "80 \n",
      " dist   :  [0.004, 0.484, 0.064, 0.459, 0.062, 0.434, 0.04, 0.47, 0.083, 0.562, 0.032, 0.519] [0.362, 0.33, 0.38, 0.342, 0.399, 0.367, 0.375, 0.346, 0.287, 0.258, 0.324, 0.291] \n",
      " pred   : [1.328, -0.442, -0.682, 0.077, -0.222, -0.441] \n",
      " rewards:  [-0.954, -0.839, -0.839, 0.298, -0.839, -0.839]\n",
      "90 \n",
      " dist   :  [0.101, 0.349, 0.085, 0.297, 0.079, 0.321, 0.1, 0.305, 0.091, 0.325, 0.116, 0.361] [0.519, 0.433, 0.584, 0.489, 0.546, 0.456, 0.56, 0.46, 0.542, 0.469, 0.504, 0.413] \n",
      " pred   : [-0.624, -0.539, 0.793, -0.206, 0.338, -0.043] \n",
      " rewards:  [-0.839, -0.839, 1.0, -0.839, 0.806, 0.874]\n",
      "100 \n",
      " dist   :  [0.014, 0.268, 0.008, 0.266, 0.013, 0.226, 0.012, 0.286, -0.021, 0.262, 0.009, 0.24] [0.648, 0.522, 0.627, 0.535, 0.681, 0.587, 0.63, 0.499, 0.652, 0.538, 0.656, 0.569] \n",
      " pred   : [1.388, 1.444, -0.412, 0.045, -0.031, -0.036] \n",
      " rewards:  [0.903, 0.997, -0.839, -0.839, -0.839, -0.839]\n",
      "110 \n",
      " dist   :  [-0.035, 0.305, -0.026, 0.281, -0.042, 0.308, -0.03, 0.26, -0.032, 0.301, -0.134, 0.316] [0.637, 0.473, 0.656, 0.484, 0.595, 0.475, 0.681, 0.532, 0.638, 0.476, 0.635, 0.478] \n",
      " pred   : [-0.283, -0.237, 0.108, 0.596, -0.084, 1.153] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.839, 0.357]\n",
      "120 \n",
      " dist   :  [-0.077, 0.354, -0.082, 0.368, -0.125, 0.339, -0.064, 0.335, -0.057, 0.334, -0.047, 0.257] [0.575, 0.387, 0.565, 0.368, 0.591, 0.415, 0.572, 0.405, 0.588, 0.404, 0.683, 0.503] \n",
      " pred   : [-0.019, -0.415, 1.249, -0.131, -0.681, -0.44] \n",
      " rewards:  [-0.839, -0.839, 0.998, -0.839, -0.839, -0.839]\n",
      "130 \n",
      " dist   :  [-0.061, 0.401, -0.057, 0.398, -0.064, 0.371, -0.036, 0.383, -0.058, 0.383, -0.074, 0.415] [0.5, 0.347, 0.492, 0.353, 0.535, 0.377, 0.512, 0.351, 0.519, 0.362, 0.47, 0.343] \n",
      " pred   : [1.341, 1.412, 1.972, 0.291, -0.066, 1.049] \n",
      " rewards:  [0.999, 0.983, 1.0, -0.839, -0.839, 0.806]\n",
      "140 \n",
      " dist   :  [0.026, 0.188, -0.008, 0.401, -0.001, 0.428, 0.004, 0.387, 0.004, 0.363, -0.094, 0.391] [0.651, 0.555, 0.422, 0.331, 0.392, 0.307, 0.43, 0.35, 0.456, 0.362, 0.433, 0.356] \n",
      " pred   : [-0.176, -0.019, -0.204, 0.184, 1.374, 1.064] \n",
      " rewards:  [-0.839, -0.326, -0.839, -0.839, 1.0, 1.0]\n",
      "150 \n",
      " dist   :  [0.035, 0.308, 0.025, 0.284, -0.026, 0.304, 0.025, 0.291, 0.016, 0.275, 0.021, 0.292] [0.398, 0.345, 0.433, 0.375, 0.405, 0.355, 0.422, 0.376, 0.446, 0.384, 0.424, 0.362] \n",
      " pred   : [-0.127, -0.392, 0.313, -0.458, 2.148, 0.78] \n",
      " rewards:  [-0.839, -0.839, -0.463, -0.839, 1.0, -0.839]\n",
      "160 \n",
      " dist   :  [0.131, 0.266, 0.136, 0.25, 0.129, 0.278, 0.125, 0.245, 0.015, 0.237, 0.152, 0.233] [0.366, 0.304, 0.387, 0.324, 0.353, 0.305, 0.393, 0.33, 0.414, 0.364, 0.398, 0.333] \n",
      " pred   : [-0.245, -0.326, 0.095, -0.205, -0.085, -0.062] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.839, -0.704]\n",
      "170 \n",
      " dist   :  [0.056, 0.255, 0.052, 0.234, 0.033, 0.278, 0.055, 0.255, 0.032, 0.265, 0.055, 0.237] [0.388, 0.349, 0.417, 0.376, 0.361, 0.334, 0.387, 0.341, 0.381, 0.354, 0.412, 0.372] \n",
      " pred   : [-0.514, -0.796, -0.484, -0.401, -0.44, -0.455] \n",
      " rewards:  [0.894, -0.839, -0.839, -0.839, -0.839, -0.839]\n",
      "180 \n",
      " dist   :  [0.063, 0.331, 0.035, 0.324, 0.062, 0.305, 0.071, 0.348, 0.033, 0.294, 0.066, 0.299] [0.35, 0.292, 0.368, 0.32, 0.379, 0.327, 0.333, 0.281, 0.405, 0.355, 0.392, 0.342] \n",
      " pred   : [-0.066, -0.093, -0.091, -0.159, -0.238, -0.108] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.839, -0.839]\n",
      "190 \n",
      " dist   :  [0.108, 0.463, 0.131, 0.466, 0.121, 0.435, 0.122, 0.435, 0.116, 0.443, 0.089, 0.296] [0.363, 0.272, 0.351, 0.253, 0.38, 0.278, 0.381, 0.282, 0.374, 0.267, 0.533, 0.435] \n",
      " pred   : [-0.549, -0.335, -0.497, -0.417, 1.201, -0.692] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, 1.0, -1.761]\n",
      "200 \n",
      " dist   :  [0.078, 0.244, 0.062, 0.149, 0.092, 0.32, -0.02, 0.264, 0.077, 0.248, 0.075, 0.269] [0.603, 0.502, 0.735, 0.643, 0.501, 0.389, 0.578, 0.47, 0.597, 0.496, 0.562, 0.446] \n",
      " pred   : [1.525, -0.097, -0.158, 0.937, -0.004, 0.085] \n",
      " rewards:  [0.999, -0.839, -0.839, 0.357, -0.839, -0.839]\n",
      "210 \n",
      " dist   :  [0.114, 0.387, 0.059, 0.423, 0.067, 0.186, 0.108, 0.384, 0.108, 0.372, 0.112, 0.409] [0.425, 0.336, 0.404, 0.323, 0.667, 0.588, 0.424, 0.332, 0.44, 0.349, 0.399, 0.312] \n",
      " pred   : [0.024, -0.346, -0.218, 0.183, -0.363, 1.302] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.839, 0.903]\n",
      "220 \n",
      " dist   :  [0.061, 0.389, 0.061, 0.351, 0.013, 0.527, -0.043, 0.45, 0.062, 0.465, 0.066, 0.475] [0.399, 0.374, 0.433, 0.399, 0.286, 0.282, 0.345, 0.316, 0.324, 0.301, 0.314, 0.29] \n",
      " pred   : [1.482, -0.36, -0.37, -0.42, -0.436, -0.408] \n",
      " rewards:  [1.0, -0.839, -0.839, -1.26, -0.839, -0.839]\n",
      "230 \n",
      " dist   :  [-0.021, 0.335, 0.017, 0.247, 0.022, 0.175, -0.036, 0.34, 0.022, 0.233, 0.018, 0.186] [0.332, 0.314, 0.41, 0.366, 0.532, 0.488, 0.317, 0.282, 0.431, 0.388, 0.513, 0.459] \n",
      " pred   : [-0.674, -0.197, -0.285, 0.973, -0.139, -0.469] \n",
      " rewards:  [-0.839, -0.326, -0.839, 0.744, -0.839, -0.363]\n",
      "240 \n",
      " dist   :  [0.119, 0.149, 0.144, 0.07, 0.156, 0.086, 0.144, 0.085, 0.137, 0.068, 0.139, 0.122] [0.406, 0.349, 0.535, 0.442, 0.494, 0.413, 0.519, 0.445, 0.55, 0.467, 0.404, 0.329] \n",
      " pred   : [0.242, -0.122, -0.312, 1.855, 0.508, -0.18] \n",
      " rewards:  [-0.839, -0.839, -0.839, 0.999, -0.345, -0.839]\n",
      "250 \n",
      " dist   :  [0.253, 0.171, 0.173, 0.104, 0.237, 0.16, 0.278, 0.19, 0.28, 0.189, 0.253, 0.215] [0.474, 0.426, 0.651, 0.599, 0.511, 0.447, 0.444, 0.392, 0.454, 0.399, 0.415, 0.375] \n",
      " pred   : [-0.209, -0.06, -0.192, -0.235, -0.347, 1.306] \n",
      " rewards:  [-0.839, -0.839, -0.326, -0.635, -0.839, 1.0]\n",
      "260 \n",
      " dist   :  [0.168, 0.276, 0.098, 0.088, 0.252, 0.309, 0.213, 0.236, 0.202, 0.223, 0.112, 0.106] [0.534, 0.551, 0.822, 0.813, 0.462, 0.468, 0.582, 0.584, 0.602, 0.605, 0.801, 0.799] \n",
      " pred   : [1.191, -0.028, -0.154, 0.048, 0.055, -0.151] \n",
      " rewards:  [0.995, -0.839, -0.839, -0.839, -0.839, -0.839]\n",
      "270 \n",
      " dist   :  [0.145, 0.168, 0.1, 0.109, 0.189, 0.291, 0.182, 0.245, 0.159, 0.258, 0.103, 0.109] [0.718, 0.719, 0.816, 0.807, 0.528, 0.534, 0.591, 0.6, 0.587, 0.611, 0.818, 0.811] \n",
      " pred   : [0.542, 2.203, 1.844, -0.274, -0.054, 1.92] \n",
      " rewards:  [-0.839, 0.994, 1.0, -1.998, -0.839, 0.999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 \n",
      " dist   :  [0.221, 0.278, 0.214, 0.291, 0.22, 0.309, 0.241, 0.304, 0.247, 0.389, 0.177, 0.323] [0.556, 0.55, 0.547, 0.523, 0.523, 0.497, 0.531, 0.516, 0.418, 0.414, 0.49, 0.478] \n",
      " pred   : [1.295, 0.303, 0.953, 0.239, 0.269, 1.986] \n",
      " rewards:  [0.984, -0.839, -0.839, -0.796, 0.485, 1.0]\n",
      "290 \n",
      " dist   :  [0.149, 0.316, 0.159, 0.348, 0.171, 0.322, 0.149, 0.29, 0.106, 0.21, 0.152, 0.303] [0.485, 0.444, 0.45, 0.408, 0.486, 0.445, 0.528, 0.484, 0.639, 0.601, 0.501, 0.464] \n",
      " pred   : [-0.112, 1.381, 0.038, -0.188, 1.144, 0.209] \n",
      " rewards:  [-0.839, 0.999, -0.839, -0.839, 0.999, -0.839]\n",
      "300 \n",
      " dist   :  [0.014, 0.364, -0.023, 0.433, -0.001, 0.302, -0.015, 0.356, -0.046, 0.441, -0.013, 0.347] [0.42, 0.379, 0.338, 0.304, 0.5, 0.448, 0.439, 0.421, 0.331, 0.296, 0.449, 0.392] \n",
      " pred   : [0.791, -0.383, -0.299, 1.51, 1.678, -0.324] \n",
      " rewards:  [0.358, -0.839, -0.839, 0.997, 1.0, -0.839]\n",
      "310 \n",
      " dist   :  [-0.058, 0.259, -0.054, 0.27, -0.034, 0.356, -0.05, 0.269, -0.078, 0.404, -0.039, 0.303] [0.485, 0.416, 0.468, 0.403, 0.359, 0.309, 0.469, 0.406, 0.319, 0.296, 0.42, 0.366] \n",
      " pred   : [0.643, 0.035, 0.941, 1.15, -0.392, 1.304] \n",
      " rewards:  [1.0, 1.0, 0.874, 1.0, -0.839, 1.0]\n",
      "320 \n",
      " dist   :  [0.03, 0.368, 0.04, 0.357, 0.055, 0.418, -0.005, 0.51, -0.016, 0.512, 0.03, 0.28] [0.373, 0.317, 0.398, 0.33, 0.332, 0.275, 0.266, 0.233, 0.267, 0.234, 0.494, 0.418] \n",
      " pred   : [0.127, 0.011, -0.228, -0.45, -0.13, -0.175] \n",
      " rewards:  [-0.463, -0.046, -0.839, -0.839, -0.839, -0.839]\n",
      "330 \n",
      " dist   :  [0.053, 0.293, 0.037, 0.251, -0.023, 0.378, 0.056, 0.294, 0.031, 0.321, 0.02, 0.218] [0.53, 0.423, 0.586, 0.466, 0.448, 0.355, 0.533, 0.426, 0.499, 0.377, 0.633, 0.504] \n",
      " pred   : [1.655, 0.056, 2.335, -0.166, 1.9, -0.17] \n",
      " rewards:  [0.994, -0.839, 0.995, -0.839, 1.0, -0.839]\n",
      "340 \n",
      " dist   :  [0.076, 0.277, 0.077, 0.276, 0.071, 0.243, 0.034, 0.135, 0.024, 0.138, 0.043, 0.267] [0.538, 0.405, 0.539, 0.406, 0.595, 0.441, 0.756, 0.607, 0.752, 0.608, 0.552, 0.414] \n",
      " pred   : [-0.221, -0.144, -0.33, 1.137, -0.024, 0.307] \n",
      " rewards:  [-0.839, -0.839, -0.839, 1.0, -0.839, 1.0]\n",
      "350 \n",
      " dist   :  [-0.015, 0.392, -0.007, 0.366, -0.021, 0.338, 0.001, 0.34, -0.004, 0.391, 0.003, 0.278] [0.475, 0.303, 0.499, 0.33, 0.535, 0.353, 0.526, 0.347, 0.476, 0.305, 0.602, 0.414] \n",
      " pred   : [0.112, 0.065, -0.054, -0.155, 1.154, -0.181] \n",
      " rewards:  [-0.839, -0.796, -0.839, -0.839, 0.995, -0.839]\n",
      "360 \n",
      " dist   :  [0.061, 0.436, 0.029, 0.219, 0.061, 0.377, 0.061, 0.414, 0.052, 0.365, 0.053, 0.386] [0.473, 0.32, 0.661, 0.505, 0.532, 0.378, 0.495, 0.34, 0.546, 0.383, 0.525, 0.36] \n",
      " pred   : [0.573, 0.046, -0.121, 0.145, 0.121, 0.095] \n",
      " rewards:  [0.903, -0.839, -0.839, -0.839, -0.839, 1.0]\n",
      "370 \n",
      " dist   :  [0.168, 0.354, 0.198, 0.416, 0.159, 0.323, 0.133, 0.4, 0.146, 0.308, 0.138, 0.389] [0.509, 0.391, 0.439, 0.333, 0.54, 0.431, 0.458, 0.37, 0.56, 0.437, 0.47, 0.384] \n",
      " pred   : [0.466, 0.781, 1.516, -0.097, 0.682, -0.232] \n",
      " rewards:  [-0.839, 0.209, 0.929, -0.839, 1.0, -0.839]\n",
      "380 \n",
      " dist   :  [0.103, 0.42, 0.129, 0.383, 0.061, 0.391, 0.145, 0.401, 0.147, 0.426, 0.166, 0.466] [0.387, 0.312, 0.431, 0.338, 0.416, 0.313, 0.415, 0.33, 0.385, 0.308, 0.346, 0.276] \n",
      " pred   : [-0.044, 1.285, 1.733, 0.38, 0.783, -0.006] \n",
      " rewards:  [-0.839, 0.733, 1.0, -0.839, 0.744, -0.839]\n",
      "390 \n",
      " dist   :  [0.099, 0.408, 0.067, 0.282, 0.076, 0.324, 0.072, 0.306, 0.074, 0.334, 0.069, 0.274] [0.354, 0.264, 0.497, 0.389, 0.446, 0.342, 0.469, 0.358, 0.434, 0.326, 0.509, 0.399] \n",
      " pred   : [1.26, -0.177, -0.138, -0.135, 1.728, 1.495] \n",
      " rewards:  [0.874, -0.839, -0.839, -1.944, 1.0, 1.0]\n",
      "400 \n",
      " dist   :  [0.101, 0.207, 0.102, 0.324, 0.154, 0.35, 0.16, 0.388, 0.146, 0.327, 0.125, 0.287] [0.548, 0.417, 0.395, 0.267, 0.368, 0.253, 0.324, 0.209, 0.392, 0.27, 0.441, 0.311] \n",
      " pred   : [0.297, -0.216, 1.331, -0.372, 0.125, -0.125] \n",
      " rewards:  [-0.839, -0.839, 0.999, -0.839, -0.839, -0.839]\n",
      "410 \n",
      " dist   :  [0.123, 0.302, 0.074, 0.111, 0.124, 0.312, 0.155, 0.406, 0.118, 0.288, 0.142, 0.374] [0.431, 0.299, 0.691, 0.566, 0.416, 0.299, 0.317, 0.207, 0.449, 0.319, 0.348, 0.222] \n",
      " pred   : [-2.95, -0.165, 0.016, -0.192, 0.071, 0.08] \n",
      " rewards:  [-11.152, -0.839, -0.839, -0.839, 0.997, -0.839]\n",
      "420 \n",
      " dist   :  [0.109, 0.323, 0.07, 0.409, 0.113, 0.377, 0.003, 0.341, 0.062, 0.415, 0.105, 0.321] [0.446, 0.33, 0.383, 0.282, 0.385, 0.272, 0.432, 0.279, 0.383, 0.283, 0.448, 0.323] \n",
      " pred   : [-0.182, 0.097, -0.024, 1.808, 1.302, -0.235] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.954, 0.806, -0.839]\n",
      "430 \n",
      " dist   :  [0.15, 0.508, 0.129, 0.408, 0.131, 0.411, 0.096, 0.479, 0.124, 0.411, 0.138, 0.408] [0.329, 0.211, 0.422, 0.291, 0.419, 0.287, 0.369, 0.245, 0.418, 0.283, 0.421, 0.291] \n",
      " pred   : [-0.122, -0.129, -3.814, 1.481, 1.617, 0.446] \n",
      " rewards:  [-0.839, -0.839, -11.152, 1.0, 0.994, 0.02]\n",
      "440 \n",
      " dist   :  [0.018, 0.174, 0.024, 0.138, 0.021, 0.206, -0.038, 0.244, -0.073, 0.229, -0.082, 0.213] [0.586, 0.423, 0.652, 0.497, 0.538, 0.381, 0.535, 0.403, 0.523, 0.357, 0.535, 0.361] \n",
      " pred   : [0.005, 1.782, -0.293, -0.264, 0.336, 1.399] \n",
      " rewards:  [-0.839, 1.0, -0.839, -0.839, 0.485, 1.0]\n",
      "450 \n",
      " dist   :  [-0.04, 0.212, -0.032, 0.198, -0.128, 0.281, -0.043, 0.209, -0.05, 0.203, -0.076, 0.237] [0.485, 0.346, 0.503, 0.353, 0.439, 0.305, 0.486, 0.342, 0.49, 0.328, 0.439, 0.285] \n",
      " pred   : [-0.101, -0.164, -0.177, -0.109, 0.064, -0.175] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.839, -0.839]\n",
      "460 \n",
      " dist   :  [-0.01, 0.438, 0.086, 0.349, 0.072, 0.346, 0.086, 0.348, 0.097, 0.362, -0.079, 0.438] [0.326, 0.246, 0.357, 0.266, 0.358, 0.255, 0.358, 0.267, 0.345, 0.257, 0.293, 0.199] \n",
      " pred   : [-0.21, -0.075, -0.261, -0.353, 0.55, -0.219] \n",
      " rewards:  [-0.839, -0.839, -0.839, -0.839, -0.085, -1.26]\n",
      "470 \n",
      " dist   :  [0.156, 0.461, 0.237, 0.371, 0.153, 0.458, 0.194, 0.282, 0.251, 0.383, 0.225, 0.343] [0.28, 0.21, 0.353, 0.273, 0.28, 0.209, 0.464, 0.363, 0.346, 0.259, 0.386, 0.302] \n",
      " pred   : [0.875, -0.229, 1.563, -0.536, -0.285, 1.695] \n",
      " rewards:  [-0.839, -0.839, 0.63, -0.839, -0.839, 0.929]\n",
      "480 \n",
      " dist   :  [0.068, 0.597, 0.072, 0.559, 0.053, 0.441, 0.066, 0.586, 0.101, 0.436, 0.14, 0.34] [0.239, 0.157, 0.266, 0.18, 0.316, 0.216, 0.248, 0.165, 0.312, 0.213, 0.383, 0.253] \n",
      " pred   : [1.332, 0.361, -0.257, -0.542, -0.123, 1.343] \n",
      " rewards:  [0.953, -0.839, -0.839, -0.839, -0.839, 1.0]\n",
      "490 \n",
      " dist   :  [-0.073, 0.574, 0.031, 0.421, 0.026, 0.405, -0.089, 0.604, -0.037, 0.438, 0.02, 0.361] [0.276, 0.196, 0.335, 0.229, 0.345, 0.24, 0.252, 0.176, 0.328, 0.235, 0.388, 0.263] \n",
      " pred   : [-0.339, 0.746, -0.101, -0.001, -0.055, -0.05] \n",
      " rewards:  [-0.839, 0.804, -0.839, -0.839, -0.839, -0.839]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(500):\n",
    "    batch = buffer.sample_batch(batch_size=6)\n",
    "\n",
    "    rewards = batch['rewards'].to(device)\n",
    "    terminals = batch['terminals'].to(device)\n",
    "    obs = batch['observations'].to(device)\n",
    "    actions = batch['actions'].to(device)\n",
    "    next_obs = batch['next_observations'].to(device)\n",
    "\n",
    "    obj_features = batch['object_features'].to(device)\n",
    "\n",
    "    # print(\"rewards\", rewards)\n",
    "\n",
    "    self.update(batch)\n",
    "    \n",
    "    if _ % 10 == 0:\n",
    "        dist = self.policy(obs, obj_features)\n",
    "        pred = self.qf1(obs, obj_features, actions)\n",
    "        print(_, \"\\n dist   : \", [round(x, 3) for x in dist.mean.flatten().tolist()], \n",
    "                  [round(x, 3) for x in dist.stddev.flatten().tolist()],\n",
    "              \"\\n pred   :\", [round(x, 3) for x in pred.flatten().tolist()],\n",
    "              \"\\n rewards: \", [round(x, 3) for x in rewards.flatten().tolist()])\n",
    "    \n",
    "#     # debug\n",
    "#     pred = self.qf1(obs, obj_features, actions)\n",
    "#     loss = self.qf_criterion(pred, rewards)\n",
    "    \n",
    "#     self.qf1_optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     self.qf1_optimizer.step()\n",
    "    \n",
    "#     if _ % 20 == 0:\n",
    "#         print(_, \"\\n debug loss: \", loss.item(), \"\\n pred:\", \n",
    "#               pred.flatten().tolist(), \"\\n rewards: \", rewards.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = self.policy(obs.to(device), obj_features.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa47896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Isaac Sim Python 3",
   "language": "python",
   "name": "isaac_sim_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
