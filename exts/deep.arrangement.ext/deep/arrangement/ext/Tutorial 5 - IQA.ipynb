{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faed99b",
   "metadata": {},
   "source": [
    "# Install pyiqa\n",
    "\n",
    "~/.local/share/ov/pkg/isaac_sim-2022.1.1/python.sh -m pip install git+https://github.com/chaofengc/IQA-PyTorch.git\n",
    "~/.local/share/ov/pkg/isaac_sim-2022.1.1/python.sh -m pip install git+https://github.com/openai/CLIP.git\n",
    "\n",
    "*(for original clip)\n",
    "\n",
    "~/.local/share/ov/pkg/isaac_sim-2022.1.1/python.sh -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9748d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ahiq', 'brisque', 'ckdn', 'clipiqa', 'clipiqa+', 'cnniqa', 'cw_ssim', 'dbcnn', 'dists', 'fid', 'fsim', 'gmsd', 'ilniqe', 'lpips', 'lpips-vgg', 'mad', 'maniqa', 'ms_ssim', 'musiq', 'musiq-ava', 'musiq-koniq', 'musiq-paq2piq', 'musiq-spaq', 'nima', 'nima-vgg16-ava', 'niqe', 'nlpd', 'nrqm', 'paq2piq', 'pi', 'pieapp', 'psnr', 'psnry', 'ssim', 'ssimc', 'vif', 'vsi']\n"
     ]
    }
   ],
   "source": [
    "import pyiqa\n",
    "import torch\n",
    "\n",
    "# list all available metrics\n",
    "print(pyiqa.list_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092dfae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba868485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model MUSIQ from /home/danny/.cache/torch/hub/checkpoints/musiq_ava_ckpt-e8d3f067.pth\n",
      "Loading pretrained model NIMA from /home/danny/.cache/torch/hub/checkpoints/NIMA_VGG16_ava-dc4e8265.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/inception_resnet_v2-940b1cd6.pth\" to /home/danny/.cache/torch/hub/checkpoints/inception_resnet_v2-940b1cd6.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/chaofengc/IQA-PyTorch/releases/download/v0.1-weights/NIMA_InceptionV2_ava-b0c77c00.pth\" to /home/danny/.cache/torch/hub/checkpoints/NIMA_InceptionV2_ava-b0c77c00.pth\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdd6cb5d5bc4722bdebb4ff5e46b0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/208M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model NIMA from /home/danny/.cache/torch/hub/checkpoints/NIMA_InceptionV2_ava-b0c77c00.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 244M/244M [00:20<00:00, 12.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "musiq_metric = pyiqa.create_metric('musiq-ava', device=torch.device('cuda'))\n",
    "nima_vgg_metric = pyiqa.create_metric('nima-vgg16-ava', device=torch.device('cuda'))  # VGG16\n",
    "nima_inception_metric = pyiqa.create_metric('nima', device=torch.device('cuda'))\n",
    "clipiqa_metric = pyiqa.create_metric('clipiqa', device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb51332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83b7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/danny/Desktop/omni-proj/DeepArrange/Example/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f54667",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img in os.listdir(\"./\"):\n",
    "    if img.find(\"png\") != -1:\n",
    "        images.append((img, Image.open(img).convert(\"RGB\").resize((224, 224))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359ce25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c5ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensors = [to_tensor(img[1]).unsqueeze(0) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c190ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [musiq_metric, nima_vgg_metric, nima_inception_metric, clipiqa_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07865eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for metric in metrics:\n",
    "    scores.append([metric(img).cpu().numpy()[0][0] for img in img_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "760a0b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4.png</th>\n",
       "      <th>dog.png</th>\n",
       "      <th>3.png</th>\n",
       "      <th>5.png</th>\n",
       "      <th>1.png</th>\n",
       "      <th>0.png</th>\n",
       "      <th>2.png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>musiq_metric</th>\n",
       "      <td>4.029762</td>\n",
       "      <td>4.538571</td>\n",
       "      <td>3.769494</td>\n",
       "      <td>4.136200</td>\n",
       "      <td>3.350562</td>\n",
       "      <td>3.352724</td>\n",
       "      <td>3.629350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nima_vgg_metric</th>\n",
       "      <td>5.271444</td>\n",
       "      <td>5.511232</td>\n",
       "      <td>5.060489</td>\n",
       "      <td>5.133384</td>\n",
       "      <td>4.524152</td>\n",
       "      <td>4.499240</td>\n",
       "      <td>4.996006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nima_inception_metric</th>\n",
       "      <td>5.310588</td>\n",
       "      <td>6.047652</td>\n",
       "      <td>5.423373</td>\n",
       "      <td>5.218344</td>\n",
       "      <td>4.652073</td>\n",
       "      <td>4.631289</td>\n",
       "      <td>5.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clipiqa_metric</th>\n",
       "      <td>0.442904</td>\n",
       "      <td>0.656748</td>\n",
       "      <td>0.439789</td>\n",
       "      <td>0.321187</td>\n",
       "      <td>0.369269</td>\n",
       "      <td>0.359274</td>\n",
       "      <td>0.407500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          4.png   dog.png     3.png     5.png     1.png  \\\n",
       "musiq_metric           4.029762  4.538571  3.769494  4.136200  3.350562   \n",
       "nima_vgg_metric        5.271444  5.511232  5.060489  5.133384  4.524152   \n",
       "nima_inception_metric  5.310588  6.047652  5.423373  5.218344  4.652073   \n",
       "clipiqa_metric         0.442904  0.656748  0.439789  0.321187  0.369269   \n",
       "\n",
       "                          0.png     2.png  \n",
       "musiq_metric           3.352724  3.629350  \n",
       "nima_vgg_metric        4.499240  4.996006  \n",
       "nima_inception_metric  4.631289  5.008500  \n",
       "clipiqa_metric         0.359274  0.407500  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores, \n",
    "             index=[\"musiq_metric\", \"nima_vgg_metric\", \"nima_inception_metric\", \"clipiqa_metric\"],\n",
    "             columns=[i[0] for i in images])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Isaac Sim Python 3",
   "language": "python",
   "name": "isaac_sim_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
